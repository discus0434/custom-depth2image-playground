{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "FjyrxFX3wXNW"
      },
      "source": [
        "# Custom Depth-to-Image Model Playground\n",
        "\n",
        "#### made by [なんか](https://twitter.com/_determina_)\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/discus0434/custom-depth2image-playground/blob/main/Custom_Depth_to_Image_Playground.ipynb)\n",
        "\n",
        "---\n",
        "\n",
        "### This notebook does:\n",
        "  - Perform Task Operation for adapting depth-to-image model to specified domain\n",
        "  - Play with the model (powered by [AUTOMATIC1111's WebUI](https://github.com/AUTOMATIC1111/stable-diffusion-webui))\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### THIS NOTEBOOK FORCES RUNTIME TO CRASH AT **SECTION 3.1**!!! \n",
        "### IF YOU RUN CELLS ALL AT FIRST, RUNTIME WILL HALT THERE. RUN SECTION 3.2 AFTER CRASHED. \n",
        "### IT IS 100% INTENDED BEHAVIOR."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5FCm3yOYNkn"
      },
      "source": [
        "# 0. Allocate GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9A6q4AW348f",
        "outputId": "4ef9e74a-119f-4501-e4c4-e613147bd6c6"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STkXwWYhYZ_z"
      },
      "source": [
        "# 1. Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCjdtk6uYSyI"
      },
      "source": [
        "## 1.1 Install Requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8ef_3K2Wam3",
        "outputId": "ab5d8f5a-a6d0-4e0f-9e61-bb0fc1b10a93"
      },
      "outputs": [],
      "source": [
        "!pip install -e git+https://github.com/CompVis/taming-transformers.git@master#egg=taming-transformers\n",
        "!pip install pytorch_lightning tensorboard omegaconf einops taming-transformers transformers kornia test-tube matplotlib pandas\n",
        "!pip install diffusers invisible-watermark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rU_LgRxobrtH"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import gc\n",
        "import copy\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KdRZ9XmsYXgI"
      },
      "source": [
        "## 1.2 Clone AUTOMATIC1111's WebUI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qrsOwFsM38UG",
        "outputId": "9250000b-ae34-45b5-eb69-54e21fe5d138"
      },
      "outputs": [],
      "source": [
        "%cd /content/\n",
        "!git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui\n",
        "%cd /content/stable-diffusion-webui"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOTeRTz4YvwN"
      },
      "source": [
        "# 2. Task Arithmetic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NkUWT_LYl4B"
      },
      "source": [
        "## 2.1 Download Model Weights (base + task-specified models)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGRg4eB_ZIxs"
      },
      "source": [
        "### Base model & depth model\n",
        "- Stable Diffusion V2.0 base\n",
        "- Stable Diffusion V2.0 depth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVnFdz6S4xwE",
        "outputId": "2777f73f-cc0c-4402-a16f-db8f64f92fa2"
      },
      "outputs": [],
      "source": [
        "!wget https://huggingface.co/stabilityai/stable-diffusion-2-base/resolve/main/512-base-ema.ckpt \\\n",
        "  -O /content/stable-diffusion-webui/models/Stable-diffusion/512-base-ema.ckpt\n",
        "!wget https://huggingface.co/stabilityai/stable-diffusion-2-depth/resolve/main/512-depth-ema.ckpt \\\n",
        "  -O /content/stable-diffusion-webui/models/Stable-diffusion/512-depth-ema.ckpt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzqtfWTdZcX3"
      },
      "source": [
        "### Model as you like"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7X_KFdaQZc8p",
        "outputId": "3ae73899-0e82-49c3-d0ce-6b853e9c4c32"
      },
      "outputs": [],
      "source": [
        "#@markdown #### MODEL MUST BE FINETUNED FROM STABLE DIFFUSION V2.0 OR ITS DESCENDANTS!!\n",
        "SPECIFIED_MODEL_URL = \"https://huggingface.co/hakurei/waifu-diffusion-v1-4/resolve/main/wd-1-4-anime_e2.ckpt\"  # @param {type: \"string\"}\n",
        "SPECIFIED_MODEL_NAME = SPECIFIED_MODEL_URL.split(\"/\")[-1]\n",
        "SPECIFIED_MODEL_PATH = f\"/content/stable-diffusion-webui/models/Stable-diffusion/{SPECIFIED_MODEL_NAME}\"\n",
        "\n",
        "!wget {SPECIFIED_MODEL_URL} -O {SPECIFIED_MODEL_PATH}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buIq6Ro3YMYe"
      },
      "source": [
        "## 2.2 Perform Task Operations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k5NKV7LScC7I"
      },
      "outputs": [],
      "source": [
        "# @markdown ### Optional Configuration\n",
        "\n",
        "# @markdown ---\n",
        "\n",
        "# @markdown #### 1. VAE replacement\n",
        "# @markdown If you wanna replace original SD's VAE with specified one, keep it checked\n",
        "REPLACE_VAE = True  # @param {type: \"boolean\"}\n",
        "\n",
        "# @markdown ---\n",
        "\n",
        "# @markdown #### 2. Set multipliers for task vectors\n",
        "# @markdown If `DEPTH = 0.5` and `SPECIFIED_MODEL = 0.1`, the outcome WILL NOT reflect effects of specified model.\n",
        "\n",
        "# @markdown If `DEPTH = 0.1` and `SPECIFIED_MODEL = 0.8`, the outcome WILL reflect effects of specified model, but not depth.\n",
        "\n",
        "# @markdown (I recommend `DEPTH = 0.45` and `SPECIFIED_MODEL = 0.75` if Waifu Diffusion)\n",
        "DEPTH = 0.45  # @param {type: \"number\"}\n",
        "SPECIFIED_MODEL = 0.75  # @param {type: \"number\"}\n",
        "\n",
        "# @markdown ---\n",
        "# @markdown #### 3. Set custom depth model name\n",
        "# @markdown Customized depth model is stored to `/content/stable-diffusion-webui/models/Stable-diffusion/{MODEL_NAME}.ckpt`.\n",
        "\n",
        "# @markdown Wanna use in local, you may download it and `yaml` file whose name is the same as the model.\n",
        "\n",
        "MODEL_NAME = \"custom-depth\"  # @param {type: \"string\"}\n",
        "MODEL_PATH = f\"/content/stable-diffusion-webui/models/Stable-diffusion/{MODEL_NAME}.ckpt\"\n",
        "MODEL_YAML_PATH = f\"/content/stable-diffusion-webui/models/Stable-diffusion/{MODEL_NAME}.yaml\"\n",
        "\n",
        "# load models\n",
        "base = torch.load(\n",
        "    \"/content/stable-diffusion-webui/models/Stable-diffusion/512-base-ema.ckpt\",\n",
        "    weights_only=True,\n",
        "    map_location=\"cuda\",\n",
        ")\n",
        "task_specified = torch.load(\n",
        "    SPECIFIED_MODEL_PATH, \n",
        "    weights_only=True,\n",
        "    map_location=\"cuda\",\n",
        ")\n",
        "\n",
        "# for saving RAM, remove unnecessary weights\n",
        "for key in set(task_specified[\"state_dict\"].keys()) | set(base[\"state_dict\"].keys()):\n",
        "    if \"cond_stage_model\" in key:\n",
        "        try:\n",
        "            del task_specified[\"state_dict\"][key], base[\"state_dict\"][key]\n",
        "        except Exception:\n",
        "            pass\n",
        "        \n",
        "    elif \"model_ema\" in key:\n",
        "        try:\n",
        "            del base[\"state_dict\"][key]\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "# make task vector of specified model\n",
        "for key in set(task_specified[\"state_dict\"].keys()):\n",
        "    if \"model.diffusion_model\" in key:\n",
        "        task_specified[\"state_dict\"][key] = task_specified[\"state_dict\"][key] - base[\"state_dict\"][key]\n",
        "\n",
        "depth = torch.load(\n",
        "    \"/content/stable-diffusion-webui/models/Stable-diffusion/512-depth-ema.ckpt\",\n",
        "    map_location=\"cpu\",\n",
        ")\n",
        "\n",
        "# perform task operation\n",
        "for key in set(depth[\"state_dict\"].keys()) & set(task_specified[\"state_dict\"].keys()):\n",
        "    # replace weight of VAE with specified weight, if REPLACE_VAE is True\n",
        "    if \"first_stage_model\" in key:\n",
        "        if REPLACE_VAE:\n",
        "            depth[\"state_dict\"][key] = task_specified[\"state_dict\"][key].cpu()\n",
        "    # don't replace weight of an input block whose dimension is different from each other\n",
        "    elif \"model.diffusion_model.input_blocks.0.0\" in key:\n",
        "        pass\n",
        "    # otherwise, add task weight\n",
        "    elif \"model.diffusion_model\" in key:\n",
        "        task_depth = depth[\"state_dict\"][key] - base[\"state_dict\"][key].cpu()\n",
        "        depth[\"state_dict\"][key] = base[\"state_dict\"][key].cpu() + (task_depth * DEPTH + task_specified[\"state_dict\"][key].cpu() * SPECIFIED_MODEL)\n",
        "\n",
        "del task_specified, base\n",
        "gc.collect()\n",
        "\n",
        "# save customized model\n",
        "torch.save(depth, MODEL_PATH)\n",
        "\n",
        "del depth\n",
        "gc.collect()\n",
        "\n",
        "# make yaml file to use depth model in webui\n",
        "with open(MODEL_YAML_PATH, \"w\") as f:\n",
        "  f.write(\n",
        "\"\"\"\n",
        "model:\n",
        "  base_learning_rate: 5.0e-07\n",
        "  target: ldm.models.diffusion.ddpm.LatentDepth2ImageDiffusion\n",
        "  params:\n",
        "    linear_start: 0.00085\n",
        "    linear_end: 0.0120\n",
        "    num_timesteps_cond: 1\n",
        "    log_every_t: 200\n",
        "    timesteps: 1000\n",
        "    first_stage_key: \"jpg\"\n",
        "    cond_stage_key: \"txt\"\n",
        "    image_size: 64\n",
        "    channels: 4\n",
        "    cond_stage_trainable: false\n",
        "    conditioning_key: hybrid\n",
        "    scale_factor: 0.18215\n",
        "    monitor: val/loss_simple_ema\n",
        "    finetune_keys: null\n",
        "    use_ema: False\n",
        "\n",
        "    depth_stage_config:\n",
        "      target: ldm.modules.midas.api.MiDaSInference\n",
        "      params:\n",
        "        model_type: \"dpt_hybrid\"\n",
        "\n",
        "    unet_config:\n",
        "      target: ldm.modules.diffusionmodules.openaimodel.UNetModel\n",
        "      params:\n",
        "        use_checkpoint: True\n",
        "        image_size: 32 # unused\n",
        "        in_channels: 5\n",
        "        out_channels: 4\n",
        "        model_channels: 320\n",
        "        attention_resolutions: [ 4, 2, 1 ]\n",
        "        num_res_blocks: 2\n",
        "        channel_mult: [ 1, 2, 4, 4 ]\n",
        "        num_head_channels: 64 # need to fix for flash-attn\n",
        "        use_spatial_transformer: True\n",
        "        use_linear_in_transformer: True\n",
        "        transformer_depth: 1\n",
        "        context_dim: 1024\n",
        "        legacy: False\n",
        "\n",
        "    first_stage_config:\n",
        "      target: ldm.models.autoencoder.AutoencoderKL\n",
        "      params:\n",
        "        embed_dim: 4\n",
        "        monitor: val/rec_loss\n",
        "        ddconfig:\n",
        "          #attn_type: \"vanilla-xformers\"\n",
        "          double_z: true\n",
        "          z_channels: 4\n",
        "          resolution: 256\n",
        "          in_channels: 3\n",
        "          out_ch: 3\n",
        "          ch: 128\n",
        "          ch_mult:\n",
        "            - 1\n",
        "            - 2\n",
        "            - 4\n",
        "            - 4\n",
        "          num_res_blocks: 2\n",
        "          attn_resolutions: [ ]\n",
        "          dropout: 0.0\n",
        "        lossconfig:\n",
        "          target: torch.nn.Identity\n",
        "\n",
        "    cond_stage_config:\n",
        "      target: ldm.modules.encoders.modules.FrozenOpenCLIPEmbedder\n",
        "      params:\n",
        "        freeze: True\n",
        "        layer: \"penultimate\"\n",
        "\"\"\"\n",
        "  )\n",
        "\n",
        "# remove models\n",
        "os.remove(\"/content/stable-diffusion-webui/models/Stable-diffusion/512-base-ema.ckpt\")\n",
        "os.remove(\"/content/stable-diffusion-webui/models/Stable-diffusion/512-depth-ema.ckpt\")\n",
        "os.remove(SPECIFIED_MODEL_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHiBCQHDi6K7"
      },
      "source": [
        "# 3. Launch WebUI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egosoG9nrLAD"
      },
      "source": [
        "## 3.1 Crash it!\n",
        "\n",
        "To free RAM and VRAM used for task operation, The next cell will force the runtime to crash deliberately.\n",
        "\n",
        "You DON'T need to restart and re-execute cells above. After crashed, just execute the next cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-l_D8D2MrST2"
      },
      "outputs": [],
      "source": [
        "os.kill(os.getpid(), 9)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "I8J_klp4stMf"
      },
      "source": [
        "## 3.2 Run AUTOMATIC1111's WebUI\n",
        "\n",
        "WebUI's URL follows `Running on public URL`.\n",
        "\n",
        "I recommend to use CLIP's penultimate layer.\n",
        "\n",
        "---\n",
        "\n",
        "#### Some instructs about prompting\n",
        "\n",
        "Using Waifu Diffusion V1.4's task vector, you may get better results if use `((masterpiece, best quality))` as prefix of prompt.\n",
        "\n",
        "And here is one example of negative prompt. One day I picked this up somewhere:\n",
        "```\n",
        "lowres, ((bad anatomy)), ((bad hands)), text, missing finger, extra digits, fewer digits, blurry, ((mutated hands and fingers)), (poorly drawn face), ((mutation)), ((deformed face)), (ugly), ((bad proportions)), ((extra limbs)), extra face, (double head), (extra head), ((extra feet)), monster, logo, cropped, worst quality, low quality, normal quality, jpeg, humpbacked, long body, long neck, ((jpeg artifacts)), ((bad composition))\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zj2YN9Cu0boJ",
        "outputId": "24ee3c2d-453a-45f4-eeb6-f4dbabb1e38a"
      },
      "outputs": [],
      "source": [
        "# run webui\n",
        "%cd /content/stable-diffusion-webui\n",
        "!COMMANDLINE_ARGS=\"--share --gradio-debug --no-half-vae\" REQS_FILE=\"requirements.txt\" python launch.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uNRkpolUvdXX"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "gCjdtk6uYSyI",
        "KdRZ9XmsYXgI",
        "ZGRg4eB_ZIxs"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
